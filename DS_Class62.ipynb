{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.2361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>57</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>138</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>77</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.1738</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  \\\n",
       "0            86  0.0856  0.0454  0.0382  0.0203  0.0385  0.0534  0.2140   \n",
       "1           153  0.0117  0.0069  0.0279  0.0583  0.0915  0.1267  0.1577   \n",
       "2            65  0.0265  0.0440  0.0137  0.0084  0.0305  0.0438  0.0341   \n",
       "3           115  0.0094  0.0333  0.0306  0.0376  0.1296  0.1795  0.1909   \n",
       "4            46  0.0373  0.0281  0.0232  0.0225  0.0179  0.0733  0.0841   \n",
       "..          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "202          57  0.0225  0.0019  0.0075  0.0097  0.0445  0.0906  0.0889   \n",
       "203          10  0.0123  0.0309  0.0169  0.0313  0.0358  0.0102  0.0182   \n",
       "204          51  0.0087  0.0046  0.0081  0.0230  0.0586  0.0682  0.0993   \n",
       "205         138  0.0164  0.0627  0.0738  0.0608  0.0233  0.1048  0.1338   \n",
       "206          77  0.0231  0.0351  0.0030  0.0304  0.0339  0.0860  0.1738   \n",
       "\n",
       "     0.1601  0.3109  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  \\\n",
       "0    0.3110  0.2837  ...  0.0172  0.0138  0.0079  0.0037  0.0051  0.0258   \n",
       "1    0.1927  0.2361  ...  0.0053  0.0029  0.0020  0.0013  0.0029  0.0020   \n",
       "2    0.0780  0.0844  ...  0.0038  0.0187  0.0156  0.0068  0.0097  0.0073   \n",
       "3    0.1692  0.1870  ...  0.0153  0.0112  0.0241  0.0164  0.0055  0.0078   \n",
       "4    0.1031  0.0993  ...  0.0008  0.0045  0.0024  0.0006  0.0073  0.0096   \n",
       "..      ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "202  0.0655  0.1624  ...  0.0034  0.0129  0.0100  0.0044  0.0057  0.0030   \n",
       "203  0.0579  0.1122  ...  0.0133  0.0265  0.0224  0.0074  0.0118  0.0026   \n",
       "204  0.0717  0.0576  ...  0.0052  0.0038  0.0079  0.0114  0.0050  0.0030   \n",
       "205  0.0644  0.1522  ...  0.0258  0.0143  0.0226  0.0187  0.0185  0.0110   \n",
       "206  0.1351  0.1063  ...  0.0106  0.0097  0.0022  0.0052  0.0072  0.0056   \n",
       "\n",
       "     0.0084  0.0090  0.0032  R  \n",
       "0    0.0102  0.0037  0.0037  0  \n",
       "1    0.0062  0.0026  0.0052  1  \n",
       "2    0.0081  0.0086  0.0095  0  \n",
       "3    0.0055  0.0091  0.0067  1  \n",
       "4    0.0054  0.0085  0.0060  0  \n",
       "..      ...     ...     ... ..  \n",
       "202  0.0035  0.0021  0.0027  0  \n",
       "203  0.0092  0.0009  0.0044  0  \n",
       "204  0.0064  0.0058  0.0030  0  \n",
       "205  0.0094  0.0078  0.0112  1  \n",
       "206  0.0038  0.0043  0.0030  0  \n",
       "\n",
       "[207 rows x 62 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 60)\n",
      "(165,)\n",
      "(21, 60)\n",
      "(21,)\n",
      "(21, 60)\n",
      "(21,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "X = data.drop(columns = ['R']).copy()\n",
    "y = data['R']\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "train_data, X_rem, train_labels, y_rem = train_test_split(X,y, train_size=0.8)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "valid_data, test_data, valid_labels, test_labels = train_test_split(X_rem,y_rem, test_size=0.5)\n",
    "\n",
    "print(train_data.shape), print(train_labels.shape)\n",
    "print(valid_data.shape), print(valid_labels.shape)\n",
    "print(test_data.shape), print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "valid_data -= mean\n",
    "valid_data /= std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model():\n",
    "     # Because we will need to instantiate\n",
    "     # the same model multiple time,\n",
    "     # we use a function to construct it.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "    input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying K-fold Validation In Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "val_mae = ''\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = valid_data\n",
    "    val_targets = valid_labels\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "    [train_data[:i * num_val_samples],\n",
    "    train_data[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "    [train_labels[:i * num_val_samples],\n",
    "    train_labels[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "    epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    # Evaluate the model on the validation data\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9047619104385376,\n",
       " 0.8571428656578064,\n",
       " 0.8095238208770752,\n",
       " 0.9047619104385376]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690476268529892"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0074 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007368633523583412, 1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data,test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
